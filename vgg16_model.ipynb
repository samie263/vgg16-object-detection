{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dutch-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "italic-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('video/video.mp4')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooperative-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "while(vidcap.isOpened()):\n",
    "    success, frame = vidcap.read()\n",
    "    if success:\n",
    "        image = cv2.imwrite('video_frames/frame'+str(count)+'.jpg', frame)\n",
    "    else:\n",
    "        break\n",
    "    count = count+1\n",
    "    \n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complete-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"video_frames/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vertical-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_images = []\n",
    "features=''\n",
    "results = []\n",
    "for image in images:\n",
    "        img = load_img(image, target_size=(224,224,3))\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        img = img/255\n",
    "        img = preprocess_input(img)\n",
    "        features = model.predict(img)\n",
    "        result = decode_predictions(features)\n",
    "        prediction_images.append(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_indexes = []\n",
    "def search_objects(obj):\n",
    "    if obj in prediction_images:\n",
    "        for item in prediction_images:\n",
    "            if item.__eq__(obj):\n",
    "                index  = prediction_images.index(item)\n",
    "                image_path = images[index] \n",
    "                frame_indexes[image_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in frame_indexes:\n",
    "    image = load_img(img, target_size=(224, 224))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "packed-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-generation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
